Documentation in progress:

## Example: Build a `JsonTokenizer` Class

(If you would like to skip the tutorial and look at the code,
you can find it in `example/json-tokenizer.ts`.)

In this tutorial, we will walk through the process of building a custom
`JsonTokenizer` class in TypeScript. This class processes a stringified
JSON input and tokenizes it into a structured format. By following this
guide, you will learn how to create a tokenizer that can handle JSON
objects and arrays, among other elements.

### Define the `JsonToken` Interface

We start by defining a custom token interface tailored to JSON
structures. This token will not only store a value and a position (as in
the base `Token` interface) but also include additional information
about the type of the JSON data.

```ts
declare interface JsonToken extends Token {
    // Stores the key for JSON objects.
    key?: string;
    // Indicates whether the token represents an array or an object.
    type?: 'array' | 'object';
    // Can either be a string, number, or an array of JsonTokens
    // (to handle complex structures like nested arrays or objects).
    value: string | number | JsonToken[];
}
```

### Create the `JsonTokenizer` Class

The `JsonTokenizer` class will extend the base `Tokenizer` class that
processes characters from a JSON string, turning them into `JsonToken`s.

Now that we've defined our `JsonToken` structure, let's create `JsonTokenizer`,
a class that extends `Tokenizer`:

```ts
class JsonTokenizer extends Tokenizer<string, JsonToken> {
    onNextToken(val: string): any {
        throw new Error('abstract method not implemented');
    }
}
```

You'll notice that `Tokenizer` provides the abstract `onNextToken`
method. This method is called by `Tokenizer`'s `tokenize()` method
whenever a `val` is unshifted from `vals`.

In the case of `JsonParser`, `onNextToken` is a good place to handle
the input JSON object's root element, which can be either an
array or an object:

```ts
class JsonTokenizer extends Tokenizer<string, JsonToken> {
    onNextToken(val: string): any {
        if (/{/.test(val)) {
            // Handle object logic
        }

        if (/\[/.test(val)) {
            // Handle array logic
        }
    }
}
```

Now, let's take a step back and consider the methods we'll have to
implement to handle the "building blocks" of a JSON object.
I propose the following:

```ts
public consumeObject(): JsonToken;
public consumeArray(): JsonToken;
public consumeWord(): JsonToken;
public consumeNumber(): JsonToken;
public consumeBoolean(): JsonToken;
```

### Consuming Words, Numbers, and Booleans

For the `consumeWord`, `consumeNumber`, and `consumeBoolean`
methods, we can take advantage of base `Tokenizer`'s `consume()`
method, which consumes a set of values until or a while
a condition is met:

```ts
// Consume chars UNTIL a second '"' character is encountered
public consumeWord(startChar = '"', endRegExp = new RegExp('"')) {
    return this.consume(startChar, 'CONSUME_ORPHAN')
        .until((val) => endRegExp.test(val))
        .join('');
}

// Consume chars WHILE numbers are encountered
public consumeNumber(startNumber: string) {
    return Number(
        this.consume(startNumber, 'CONSUME_ORPHAN')
            .while((val) => /\d/.test(val))
            .join('')
    );
}

// Consume chars WHILE numbers are encountered
public boolean(startChar: string) {
    return Boolean(
        this.consume(startChar, 'CONSUME_ORPHAN')
            .while((val) => /\w/.test(val))
            .join('')
    );
}
```

### Consuming Objects and Arrays

The `consumeObject` and `consumeArray` methods are slightly more complex
and require recursive thinking. After all, an array can be composed of objects,
and the `value` of an object can be an array.

To handle JSON objects and arrays, we can create methods that
recursively tokenize the inner elements of the objects and arrays:

```ts
// Consume chars until the '}' character is encountered
public consumeObject(): JsonToken {
    return {
        position: this.position,
        value: /** consume inner object code */,
        type: 'object'
    };
}

// Consume chars until the ']' character is encountered
public consumeArray(): JsonToken {
    return {
        position: this.position,
        value: /** consume inner array code */,
        type: 'array'
    };
}
```

#### Consume Inner Objects and Arrays

Right now, we have a comment as a placeholder for `value` in the return
token of both methods. We could write two methods: one for consuming
inner arrays and one for consuming inner values; however, consuming objects and arrays
is a similar problem. We must consume characters until the terminating character is reached--
in the case of an object, a close brace (`}`) and in the case of an array,
a close bracket (`]`).

Let's create a single method that can consume both inner objects and arrays:

```ts
private _consumeInner(endToken: ']' | '}'): JsonToken[] {
    const innerVals: JsonToken[] = [];

    // Init value so we don't have to deal with a `string | undefined` type.
    let val = '$';
    while (val !== endToken) {
        // handle val consumption
    }

    return innervals;
}
```

When handling value consumption, we can make a few assumptions
(at least for the purposes of this tutorial):

1. We should ignore whitespace
2. If we encounter a `[`, we know that we have to consume an array
3. If we encounter a `{`, we know that we have to consume an object
4. If we encounter a `\d`, this has to be an array element, since numbers cannot be keys
5. If we encounter a `\w`, this has to be a boolean or an invalid string
6. If we encounter a `"`, we know that we have either a key or an array value
7. If we encounter a `:` after consuming the word, we know that we have encountered a key,
   and we have to consume its value

#### Assumption 1: Ignore Whitespace

Regarding the first assumption, there may be other places in the code where we have to ignore whitespace,
and depending on the way the input is formatted, we might have to ignore multiple
whitespace characters in a row. Let's create an abstract method
that consumes whitespace until a non-whitespace character is encountered:

```ts
private _consumeWhitespace(value: string) {
    // Shift values until a non-whitespace character is encountered
    while (/\s/.test(value)) value = this.next();
    return value;
}
```

This method accepts a character that may or may not be a whitespace.
If it's not a whitespace, the character is returned; if it is, we
take advantage of `Tokenizer`'s `next()` method, which returns the next
`val` from `vals` or throws an error if there are no more characters to unshift.

#### Assumption 2-5: Consume Arrays and Objects

We have already written methods to consume numbers and booleans.
We have yet to write our functions that will consume arrays and objects,
but we know we'll need to call them in this method:

```ts
private _consumeInner(endToken: ']' | '}'): JsonToken[] {
    const innerVals: JsonToken[] = [];

    // Init value so we don't have to deal with a `string | undefined` type.
    let val = '$';
    while (val !== endToken) {
        if (val === '[') {
            innerVals.push(consumeArray());
            continue;
        }

        if (val === '{') {
            innerVals.push(consumeObject());
            continue;
        }

        // regexp that indicates the start of a digit
        if (/\d/.test(val)) {
            innerVals.push({
                value: this.consumeNumber(val),
                position: this.position
            });
            continue;
        }

        // If an unquoted string is encountered, it must be a boolean or invalid
        if (/\w/.test(value)) {
            return {
                key,
                value: this.consumeBoolean(value),
                position: this.position
            };
        }
    }

    return innervals;
}
```

#### Assumption 6: Consume a Key or Word

We have written all the code we need to consume either a key in a key/value pair
or a word:

```ts
private _consumeInner(endToken: ']' | '}'): JsonToken[] {
    const innerVals: JsonToken[] = [];

    // Init value so we don't have to deal with a `string | undefined` type.
    let val = '$';
    while (val !== endToken) {

        ...

        if (val === '"') {
            // Assume for now the word is a key
            const key = this.consumeWord();
            // Consume whitespace until a non whitespace character is reached
            const next = this._consumeWhitespace(this.next());

            // If the next character is not a colon, we know that `key` is
            // actually a value
            if (next !== ':') {
                // Unshift `next` to the top of `vals` so we can process it
                // in the next iteration of the `while` loop
                this.vals.unshift(next);

                // Having a value that is not a key is only valid if this is an array element.
                // Otherwise, we have a key without a value.
                // If we were to implement validation, we would have to check if this structure is an array.
                // If it's an object, we'd want to throw an error with its position
                innerVals.push({
                    value: key,
                    position: this.position
                });

                continue;
            }

            // If `next` is a colon, we'll consume this key's value
            innerVals.push(this.consumeKeyValue(key));
            continue;
        }
    }

    return innervals;
}
```

#### Assumption 7: Consuming a Key's Value

If we determine that `key` is in fact a `key`, we need to consume its value.
We again need to think recursively, as a value could be an array, object,
string, number, or boolean. Let's create a method that consumes
a key's value:

```ts
private _consumeKeyValue(key: string): JsonToken {
    let value = this._consumeWhitespace(this.next());

    // '{' indicates that the value is the start
    // of an inner object.
    if (value === '{') {
        return {
            key,
            value: /* consume object logic */,
            position: this.position,
            type: 'object'
        };
    }

    // '[' indicates that the value is the start
    // of an inner array
    if (value === '[') {
        return {
            key,
            value: /* consume array logic */,
            position: this.position,
            type: 'array'
        };
    }

    // '"' indicates that the value is the start of a string value
    if (value === '"') {
        return {
            key,
            value: this.consumeWord(),
            position: this.position
        };
    }

    // regexp that indicates the start of a digit
    if (/\d/.test(value)) {
        return {
            key,
            value: this.consumeNumber(value),
            position: this.position
        };
    }

    // If an unquoted string is encountered, it must be a boolean or invalid
    if (/\w/.test(value)) {
        return {
            key,
            value: this.consumeBoolean(value),
            position: this.position
        }
    }

    throw 'Unexpected char encountered "' + value + '"';
}
```

### Putting It All Together

```ts
interface JsonToken extends Token {
    key?: string;
    type?: 'array' | 'object';
    value: string | number | JsonToken[];
}

class JsonTokenizer extends Tokenizer<string, JsonToken> {
    public onNextToken(val: string): any {
        if (/{/.test(val)) {
            return this.tokens.push(this.consumeObject());
        }

        if (/\[/.test(val)) {
            return this.tokens.push(this.consumeArray());
        }
    }

    /**
     * Consume an object's children
     */
    public consumeObject(): JsonToken {
        return {
            position: this.position,
            value: this._consumeInner('}'),
            type: 'object'
        };
    }

    /**
     * Consume an array's elements
     */
    public consumeArray(): JsonToken {
        return {
            position: this.position,
            value: this._consumeInner(']'),
            type: 'array'
        };
    }

    /**
     * Consumes vals until a non-whitespace val is encountered
     * @param value A value from `vals`
     * @returns The next value unshifted from `vals` that is not a
     * whitespace character
     */
    private _consumeWhitespace(value: string) {
        while (/\s/.test(value)) value = this.next();
        return value;
    }

    /**
     * Consumes chars until `endRegExp` matches the char.
     * @param startChar (default: `"`) The char that starts the word
     * @param endRegExp (default: `/"/`) A regular expression that marks the end
     * of the "word"
     */
    public consumeWord(startChar = '"', endRegExp = /"/) {
        return this.consume(startChar, 'CONSUME_ORPHAN')
            .until((val) => endRegExp.test(val))
            .join('');
    }

    /**
     * Consumes a number, given the number char that was unshifted
     * @param startNumber The number character that starts the number
     * @returns The consumed number
     */
    public consumeNumber(startNumber: string) {
        return Number(
            this.consume(startNumber, 'CONSUME_ORPHAN')
                .while((val) => /\d/.test(val))
                .join('')
        );
    }

    /**
     * Consumes an inner array or object
     * @param endToken The token that marks the end of the inner array
     * or object
     * @returns An array or object token with its sub elements
     */
    private _consumeInner(endToken: ']' | '}') {
        const innerVals: JsonToken[] = [];

        let val = '$';
        while (val !== endToken) {
            val = this.next();

            if (val === ',') continue;

            if (val === '[') {
                innerVals.push(this.consumeArray());
                continue;
            }

            if (val === '{') {
                innerVals.push(this.consumeObject());
                continue;
            }

            if (val === '"') {
                const key = this.consumeWord();
                const next = this._consumeWhitespace(this.next());

                if (next !== ':') {
                    this.vals.unshift(next);
                    innerVals.push({
                        value: key,
                        position: this.position
                    });
                    continue;
                }

                innerVals.push(this.consumeKeyValue(key));
                continue;
            }

            if (/\d/.test(val)) {
                innerVals.push({
                    value: this.consumeNumber(val),
                    position: this.position
                });
                continue;
            }
        }

        return innerVals;
    }

    /**
     * Consumes the value of a key/value pair
     * @param key The key in a key/value pair
     * @returns A token whose value is a string, number,
     * object, or array
     */
    public consumeKeyValue(key: string): JsonToken {
        let value = this._consumeWhitespace(this.next());

        if (value === '{') {
            return {
                key,
                value: this.consumeObject().value,
                position: this.position,
                type: 'object'
            };
        }

        if (value === '[') {
            return {
                key,
                value: this.consumeArray().value,
                position: this.position,
                type: 'array'
            };
        }

        if (value === '"') {
            return {
                key,
                value: this.consumeWord(),
                position: this.position
            };
        }

        if (/\d/.test(value)) {
            return {
                key,
                value: this.consumeNumber(value),
                position: this.position
            };
        }

        throw 'Unexpected char encountered "' + value + '"';
    }
}
```

To see the `JsonTokenizer` in action, let's use a JSON string and
tokenize it using the methods we've built.

```ts
const jsonString = '{"name": "John", "age": 30, "children": ["Jane", "Jack"]}';
const tokenizer = new JsonTokenizer(jsonString.split(''));
tokenizer.tokenize();

console.log(tokenizer.tokens);
```

In this example, we:

1.  Split the JSON string into an array of characters.
2.  Initialize the `JsonTokenizer` with the array of characters.
3.  Call `tokenize()` to process the entire input.

The tokenizer will break the JSON string down into tokens for objects,
arrays, keys, and values.

### Output Example

The result of tokenization will be a structured array of `JsonToken`
objects. Here's a rough idea of what the output might look like:

```ts
[
    { type: "object", value: [...] },
    { key: "name", value: "John", position: 2 },
    { key: "age", value: 30, position: 15 },
    { key: "children", value: [{...}, {...}], position: 25 }
]
```

This structured output provides a clean and hierarchical view of the
JSON data, which can be used in further processing, such as parsing or
interpreting the JSON.

### Conclusion

By following this tutorial, you have built a robust `JsonTokenizer` that
can parse and tokenize JSON objects and arrays. This class can be
extended to handle more complex JSON structures and additional data
types. Here\'s a recap of the steps involved:

1.  **Define the `JsonToken` interface** to structure tokens with object
    or array types.
2.  **Implement `onNextToken()`** to identify and delegate token
    processing based on the type of JSON element.
3.  **Create methods to handle JSON objects and arrays**, using
    recursive logic to process nested structures.
4.  **Handle whitespace and other insignificant characters** to ensure
    clean tokenization.

This tokenizer can serve as a foundation for building more complex
parsers and interpreters for JSON-like data formats.

### Further Processing

Using the `JsonTokenizer` we just created, we can create a namespace
`MyJson` that has a `parse` method that iterates over the tokens
and create an object or array from them:

```ts
namespace MyJSON {
    /**
     * Parses the final JSON object from its tokens.
     */
    export function parse<T>(jsonString: string) {
        const tokens = new JsonTokenizer([...jsonString]).tokenize().tokens;

        const root = tokens.shift();

        if (!root) throw new SyntaxError('JSON object must have a root token.');

        const { type, value } = root;

        if (!Array.isArray(value)) {
            throw new SyntaxError('JSON object root token must have values.');
        }

        if (type === 'array') return <T>parseArray(value);
        if (type === 'object') return <T>parseObject(value);

        throw new Error('Cannot parse JSON object');
    }

    function parseObject(objChildren: JsonToken[]) {
        const obj: any = {};

        for (let { value, key, type } of objChildren) {
            key = key?.replace(/"/g, '');

            if (Array.isArray(value) && key) {
                if (type === 'array') {
                    obj[key] = parseArray(value);
                    continue;
                }

                if (type === 'object') {
                    obj[key] = parseObject(value);
                    continue;
                }
            }

            if (key) {
                if (typeof value === 'string') value = value.replace(/"/g, '');
                obj[key] = value;
            }
        }

        return obj;
    }

    function parseArray(arrChildren: JsonToken[]) {
        const arr: any[] = [];

        for (let { value, type } of arrChildren) {
            if (Array.isArray(value)) {
                if (type === 'array') {
                    arr.push(parseArray(value));
                    continue;
                }

                if (type === 'object') {
                    arr.push(parseObject(value));
                    continue;
                }
            }

            if (typeof value === 'string') value = value.replace(/"/g, '');
            arr.push(value);
        }

        return arr;
    }
}
```
